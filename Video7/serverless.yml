service: sls-create-glue-crawler

useDotenv: true


provider:
  name: aws
  region: us-east-1

  stackTags:
    product: datateam
    env: qa
    created-date: 2022-04-05
    team: data
    customer-impact: false
    terraform: false

plugins:
  - serverless-glue

Glue:
  bucketDeploy: ${env:GLUE_BUCKET}
  tempDirBucket: ${env:GLUE_BUCKET_TEM}
  tempDirS3Prefix: 'temp/'
  jobs:
    - name: ${env:JOB_NAME}
      scriptPath: ${env:GLUE_SCRIPT_PYTHON_FILE_NAME}
      type: spark
      glueVersion: "python3-3.0"
      role: ${env:GLUE_ROLE_ARN}
      MaxConcurrentRuns: 3
      DefaultArguments:
        jobBookmarkOption: "job-bookmark-enable"
        customArguments:
          job-bookmark-option: "job-bookmark-enable"
      tempDir: true
      WorkerType: Standard
      NumberOfWorkers: 3
      Timeout: 2880
      MaxRetries: 1
      SupportFiles:
        - local_path: ${env:LOCAL_PATH}
          s3_bucket: ${env:GLUE_BUCKET}
          s3_prefix: ${env:S3_PREFIX_GLUE_SCRIPT}
          execute_upload: True
  triggers:
    - name: glue-script-trigger # Required
      Description: "This glue job shall be fired at cron "
      StartOnCreation: True # Optional, True or False
      schedule: 0 12 * * ? * # Optional, CRON expression. The trigger will be created with On-Demand type if the schedule is not provided.
      actions: # Required. One or more jobs to trigger
        - name: ${env:JOB_NAME}


resources:
  Resources:
    GlueDatabase:
      Type: AWS::Glue::Database
      Properties:
        CatalogId: ${env:ACCOUNT}
        DatabaseInput:
          Name: ${env:DB_NAME}

    TableGlueCrawler:
      Type: AWS::Glue::Crawler
      Properties:
        DatabaseName: ${env:DB_NAME}
        Name: ${env:CRAWLER_NAME}
        RecrawlPolicy:
          RecrawlBehavior: CRAWL_EVERYTHING
        Role: ${env:GLUE_ROLE_ARN}
        SchemaChangePolicy:
          DeleteBehavior: DEPRECATE_IN_DATABASE
        Targets:
          S3Targets:
            - Path: ${env:CRAWLER_TARGET_PATH}

